# src/ - Core Modules

## ğŸ“Œ ê°œìš”

ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•µì‹¬ ëª¨ë“ˆ. scriptsëŠ” ì´ ëª¨ë“ˆë“¤ì„ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„ë©ë‹ˆë‹¤.

---

## ğŸ“‚ êµ¬ì¡°

```
src/
â”œâ”€â”€ utils.py          # âœ… í•µì‹¬ â€” ê²½ë¡œ, Config ìƒì†/ë³‘í•©, seed, ê²½ë¡œ í—¬í¼, ê²°ê³¼ ê¸°ë¡
â”œâ”€â”€ data_loader.py    # [DEPRECATED] ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
â”œâ”€â”€ model.py          # [DEPRECATED] YOLO ëª¨ë¸ ë˜í¼
â”œâ”€â”€ trainer.py        # [DEPRECATED] í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬
â””â”€â”€ inference.py      # [DEPRECATED] ì¶”ë¡  ë° ê²°ê³¼ ì²˜ë¦¬
```

> **NOTE**: `utils.py`ë§Œ í˜„ì¬ íŒŒì´í”„ë¼ì¸(scripts/)ì—ì„œ í™œë°œíˆ ì‚¬ìš©ë©ë‹ˆë‹¤.
> ë‚˜ë¨¸ì§€ 4ê°œ ëª¨ë“ˆì€ ì°¸ê³ ìš©ìœ¼ë¡œ ë³´ì¡´ë˜ë©°, ì‹¤ì œ í•™ìŠµ/ì¶”ë¡ ì€ scriptsì—ì„œ ultralytics.YOLOë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤.

---

## ğŸ“„ ëª¨ë“ˆ ìƒì„¸

### `utils.py` (í•µì‹¬ ëª¨ë“ˆ)
**ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜**

- `setup_project_paths()`: í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì • ë° í´ë” ìƒì„±
- `set_seed()`: ì¬í˜„ì„±ì„ ìœ„í•œ seed ê³ ì •
- `load_config()`: Config ë¡œë“œ (JSON/YAML, `_base_` ìƒì† ì§€ì›)
- `merge_configs()`: ë‘ config dict ê¹Šì€ ë³‘í•© (base + override)
- `get_dataset_dir()`: YOLO ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ê²½ë¡œ í—¬í¼
- `get_data_yaml()`: data.yaml ê²½ë¡œ í—¬í¼
- `save_config()`: Config ì €ì¥ (JSON/YAML)
- `create_run_manifest()`: ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ìƒì„±
- `record_result()`: ê²°ê³¼ ê¸°ë¡ (CSV + JSONL)

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from src.utils import setup_project_paths, set_seed, load_config, get_data_yaml

# ê²½ë¡œ ì„¤ì •
paths = setup_project_paths(run_name="exp001", create_dirs=True)

# Seed ê³ ì •
set_seed(42, deterministic=True)

# Config ë¡œë“œ (_base_ ìƒì† ìë™ ì²˜ë¦¬)
config = load_config("configs/experiments/exp001_baseline.yaml")

# YOLO data.yaml ê²½ë¡œ
data_yaml = get_data_yaml(paths)
```

---

### `data_loader.py` [DEPRECATED]
**ë°ì´í„°ì…‹ ë¡œë”© ë° ì „ì²˜ë¦¬** (í˜„ì¬ íŒŒì´í”„ë¼ì¸ì—ì„œ ë¯¸ì‚¬ìš©)

#### COCODataset
COCO í¬ë§· ë°ì´í„°ì…‹ ë¡œë” (PyTorch Dataset)

```python
from src.data_loader import COCODataset, load_split_ids

# Split IDs ë¡œë“œ
train_ids = load_split_ids("data/processed/cache/exp001/splits/train_ids.txt")

# Dataset ìƒì„±
dataset = COCODataset(
    coco_json_path="data/processed/cache/exp001/train_merged_coco.json",
    image_root="data/raw/train_images",
    split_ids=train_ids,
)

# ì‚¬ìš©
image, target = dataset[0]
print(target["boxes"], target["labels"])
```

#### YOLODatasetWrapper
YOLO ë°ì´í„°ì…‹ ë˜í¼ (data.yaml ê¸°ë°˜)

```python
from src.data_loader import YOLODatasetWrapper

wrapper = YOLODatasetWrapper("data/processed/datasets/exp001_yolo/data.yaml")
print(wrapper.get_num_classes())  # 56
print(wrapper.get_class_names())  # ['class1', 'class2', ...]
```

---

### `model.py` [DEPRECATED]
**YOLO ëª¨ë¸ ë˜í¼** (í˜„ì¬ íŒŒì´í”„ë¼ì¸ì—ì„œ ë¯¸ì‚¬ìš©)

#### YOLOModel
Ultralytics YOLO ëª¨ë¸ ê´€ë¦¬

```python
from src.model import YOLOModel

# ëª¨ë¸ ìƒì„±
model = YOLOModel(model_name="yolov8s.pt", device="0")

# í•™ìŠµ
results = model.train(
    data_yaml="data/processed/datasets/exp001_yolo/data.yaml",
    epochs=80,
    imgsz=768,
    batch=8,
)

# ì¶”ë¡ 
results = model.predict(source="data/raw/test_images/", conf=0.25)

# í‰ê°€
val_results = model.validate()
```

---

### `trainer.py` [DEPRECATED]
**í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬** (í˜„ì¬ íŒŒì´í”„ë¼ì¸ì—ì„œ ë¯¸ì‚¬ìš©)

#### Trainer
Config ê¸°ë°˜ í•™ìŠµ ì‹¤í–‰

```python
from src.trainer import Trainer

# Trainer ìƒì„±
trainer = Trainer(
    run_name="exp001",
    config="configs/experiments/exp001_baseline.yaml",
    device="0",
)

# í•™ìŠµ ì‹¤í–‰
results = trainer.train(
    data_yaml="data/processed/datasets/exp001_yolo/data.yaml",
)

# í‰ê°€
eval_results = trainer.evaluate(split="val")

# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
trainer.load_checkpoint("runs/exp001/checkpoints/best.pt")
```

**ì£¼ìš” ê¸°ëŠ¥**:
- Config ê¸°ë°˜ ìë™ ì„¤ì •
- ì¬í˜„ì„± ë³´ì¥ (seed, deterministic)
- Run manifest ìƒì„±
- ê²°ê³¼ ìë™ ê¸°ë¡

---

### `inference.py` [DEPRECATED]
**ì¶”ë¡  ë° ê²°ê³¼ ì²˜ë¦¬** (í˜„ì¬ íŒŒì´í”„ë¼ì¸ì—ì„œ ë¯¸ì‚¬ìš©, 5_submission.pyê°€ ì§ì ‘ ì²˜ë¦¬)

#### Inferencer
ì¶”ë¡  ì‹¤í–‰ ë° ì œì¶œ íŒŒì¼ ìƒì„±

```python
from src.inference import Inferencer

# Inferencer ìƒì„±
inferencer = Inferencer(
    checkpoint_path="runs/exp001/checkpoints/best.pt",
    device="0",
)

# ì¶”ë¡  ì‹¤í–‰
results = inferencer.predict(
    source="data/raw/test_images/",
    conf=0.25,
    iou=0.45,
)

# ì œì¶œ íŒŒì¼ ìƒì„±
inferencer.create_submission_csv(
    results=results,
    output_path="artifacts/exp001/submissions/submission.csv",
    top_k=4,  # Top-4 only
)

# ê²€ì¦
validation = inferencer.validate_submission_csv(
    "artifacts/exp001/submissions/submission.csv"
)
print(validation["valid"])  # True/False
```

**ì£¼ìš” ê¸°ëŠ¥**:
- Top-K í•„í„°ë§
- submission.csv ìƒì„±
- ì œì¶œ íŒŒì¼ ê²€ì¦
- DataFrame ë³€í™˜

---

## ğŸ”— ëª¨ë“ˆ ê°„ ê´€ê³„

```
scripts/ (0~5_*.py)
  â†“ (ì§ì ‘ ì‚¬ìš©)
src/
  â””â”€â”€ utils.py          â† ì „ ìŠ¤í¬ë¦½íŠ¸ê°€ ì‚¬ìš© (ê²½ë¡œ, config, seed, ê¸°ë¡)

[DEPRECATED - ì°¸ê³ ìš©]
  â”œâ”€â”€ data_loader.py    â† COCODataset, YOLO wrapper
  â”œâ”€â”€ model.py          â† YOLOModel (Ultralytics ë˜í¼)
  â”œâ”€â”€ trainer.py        â† utils + model (í•™ìŠµ ì‹¤í–‰)
  â””â”€â”€ inference.py      â† model (ì¶”ë¡  ì‹¤í–‰)
```

---

## âœ… ì „ì²´ ì›Œí¬í”Œë¡œìš° ì˜ˆì‹œ

```python
# 1. ê²½ë¡œ ì„¤ì •
from src.utils import setup_project_paths, set_seed, load_config

paths = setup_project_paths("exp001", create_dirs=True)
set_seed(42)
config = load_config("configs/experiments/exp001_baseline.yaml")

# 2. ë°ì´í„° ë¡œë”©
from src.data_loader import YOLODatasetWrapper

yolo_data = YOLODatasetWrapper(paths["DATA"] / "datasets/exp001_yolo/data.yaml")
print(f"Classes: {yolo_data.get_num_classes()}")

# 3. í•™ìŠµ
from src.trainer import Trainer

trainer = Trainer(run_name="exp001", config=config)
trainer.train(data_yaml=yolo_data.get_data_yaml_path())

# 4. í‰ê°€
eval_results = trainer.evaluate(split="val")

# 5. ì¶”ë¡ 
from src.inference import Inferencer

inferencer = Inferencer(checkpoint_path=paths["CKPT"] / "best.pt")
results = inferencer.predict_and_filter_top_k(
    source=paths["TEST_IMAGES"],
    top_k=4,
    conf=0.25,
)

# 6. ì œì¶œ íŒŒì¼ ìƒì„±
inferencer.create_submission_csv(
    results=results,
    output_path=paths["SUBMISSIONS"] / "submission.csv",
    top_k=4,
)
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥:

```bash
# utils.py í…ŒìŠ¤íŠ¸
python src/utils.py

# data_loader.py í…ŒìŠ¤íŠ¸
python src/data_loader.py

# model.py í…ŒìŠ¤íŠ¸
python src/model.py

# trainer.py í…ŒìŠ¤íŠ¸
python src/trainer.py

# inference.py í…ŒìŠ¤íŠ¸
python src/inference.py
```

---

## ğŸ“Š ì½”ë“œ í†µê³„

- **utils.py**: 19KB, 600+ lines
- **data_loader.py**: 8.4KB, 280+ lines
- **model.py**: 9.1KB, 300+ lines
- **trainer.py**: 10KB, 330+ lines
- **inference.py**: 9.9KB, 320+ lines

**ì´ ì½”ë“œëŸ‰**: ~56KB, 1,830+ lines

---

## ğŸ”§ í™•ì¥ ê°€ëŠ¥ì„±

### í–¥í›„ ì¶”ê°€ ê°€ëŠ¥í•œ ê¸°ëŠ¥

1. **data_loader.py**
   - Custom augmentation pipeline
   - Multi-scale training support
   - Cached dataset (faster loading)

2. **model.py**
   - Ensemble ëª¨ë¸ ì§€ì›
   - TTA (Test-Time Augmentation)
   - Model pruning/quantization

3. **trainer.py**
   - Multi-GPU í•™ìŠµ (DDP)
   - Mixed precision training (AMP)
   - Learning rate finder

4. **inference.py**
   - Batch inference optimization
   - Visualization tools
   - Uncertainty estimation

---

**êµ¬í˜„ ì™„ë£Œ**: 2026-02-06
**ë‹´ë‹¹**: @DM
**ìƒíƒœ**: utils.py ë¦¬íŒ©í† ë§ ì™„ë£Œ âœ… (config ìƒì†, flat êµ¬ì¡°, ê²½ë¡œ í—¬í¼)
