# src/ - Core Modules

## ğŸ“Œ ê°œìš”

ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•µì‹¬ ëª¨ë“ˆ. scriptsëŠ” ì´ ëª¨ë“ˆë“¤ì„ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„ë©ë‹ˆë‹¤.

---

## ğŸ“‚ êµ¬ì¡°

```
src/
â”œâ”€â”€ utils.py          # ê³µí†µ ìœ í‹¸ë¦¬í‹° (ê²½ë¡œ, Config, ì¬í˜„ì„±, ë¡œê¹…)
â”œâ”€â”€ data_loader.py    # ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
â”œâ”€â”€ model.py          # YOLO ëª¨ë¸ ë˜í¼
â”œâ”€â”€ trainer.py        # í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬
â””â”€â”€ inference.py      # ì¶”ë¡  ë° ê²°ê³¼ ì²˜ë¦¬
```

---

## ğŸ“„ ëª¨ë“ˆ ìƒì„¸

### `utils.py`
**ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜**

- `setup_project_paths()`: í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì • ë° í´ë” ìƒì„±
- `set_seed()`: ì¬í˜„ì„±ì„ ìœ„í•œ seed ê³ ì •
- `load_config()` / `save_config()`: Config ê´€ë¦¬ (JSON/YAML)
- `create_run_manifest()`: ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ìƒì„±
- `record_result()`: ê²°ê³¼ ê¸°ë¡ (CSV + JSONL)

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from src.utils import setup_project_paths, set_seed, load_config

# ê²½ë¡œ ì„¤ì •
paths = setup_project_paths(run_name="exp001", create_dirs=True)

# Seed ê³ ì •
set_seed(42, deterministic=True)

# Config ë¡œë“œ
config = load_config("configs/base.yaml")
```

---

### `data_loader.py`
**ë°ì´í„°ì…‹ ë¡œë”© ë° ì „ì²˜ë¦¬**

#### COCODataset
COCO í¬ë§· ë°ì´í„°ì…‹ ë¡œë” (PyTorch Dataset)

```python
from src.data_loader import COCODataset, load_split_ids

# Split IDs ë¡œë“œ
train_ids = load_split_ids("data/processed/cache/exp001/splits/train_ids.txt")

# Dataset ìƒì„±
dataset = COCODataset(
    coco_json_path="data/processed/cache/exp001/train_merged_coco.json",
    image_root="data/raw/train_images",
    split_ids=train_ids,
)

# ì‚¬ìš©
image, target = dataset[0]
print(target["boxes"], target["labels"])
```

#### YOLODatasetWrapper
YOLO ë°ì´í„°ì…‹ ë˜í¼ (data.yaml ê¸°ë°˜)

```python
from src.data_loader import YOLODatasetWrapper

wrapper = YOLODatasetWrapper("data/processed/datasets/exp001_yolo/data.yaml")
print(wrapper.get_num_classes())  # 56
print(wrapper.get_class_names())  # ['class1', 'class2', ...]
```

---

### `model.py`
**YOLO ëª¨ë¸ ë˜í¼**

#### YOLOModel
Ultralytics YOLO ëª¨ë¸ ê´€ë¦¬

```python
from src.model import YOLOModel

# ëª¨ë¸ ìƒì„±
model = YOLOModel(model_name="yolov8s.pt", device="0")

# í•™ìŠµ
results = model.train(
    data_yaml="data/processed/datasets/exp001_yolo/data.yaml",
    epochs=80,
    imgsz=768,
    batch=8,
)

# ì¶”ë¡ 
results = model.predict(source="data/raw/test_images/", conf=0.25)

# í‰ê°€
val_results = model.validate()
```

---

### `trainer.py`
**í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬**

#### Trainer
Config ê¸°ë°˜ í•™ìŠµ ì‹¤í–‰

```python
from src.trainer import Trainer

# Trainer ìƒì„±
trainer = Trainer(
    run_name="exp001",
    config="configs/experiments/exp001_baseline.yaml",
    device="0",
)

# í•™ìŠµ ì‹¤í–‰
results = trainer.train(
    data_yaml="data/processed/datasets/exp001_yolo/data.yaml",
)

# í‰ê°€
eval_results = trainer.evaluate(split="val")

# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
trainer.load_checkpoint("runs/exp001/checkpoints/best.pt")
```

**ì£¼ìš” ê¸°ëŠ¥**:
- Config ê¸°ë°˜ ìë™ ì„¤ì •
- ì¬í˜„ì„± ë³´ì¥ (seed, deterministic)
- Run manifest ìƒì„±
- ê²°ê³¼ ìë™ ê¸°ë¡

---

### `inference.py`
**ì¶”ë¡  ë° ê²°ê³¼ ì²˜ë¦¬**

#### Inferencer
ì¶”ë¡  ì‹¤í–‰ ë° ì œì¶œ íŒŒì¼ ìƒì„±

```python
from src.inference import Inferencer

# Inferencer ìƒì„±
inferencer = Inferencer(
    checkpoint_path="runs/exp001/checkpoints/best.pt",
    device="0",
)

# ì¶”ë¡  ì‹¤í–‰
results = inferencer.predict(
    source="data/raw/test_images/",
    conf=0.25,
    iou=0.45,
)

# ì œì¶œ íŒŒì¼ ìƒì„±
inferencer.create_submission_csv(
    results=results,
    output_path="artifacts/exp001/submissions/submission.csv",
    top_k=4,  # Top-4 only
)

# ê²€ì¦
validation = inferencer.validate_submission_csv(
    "artifacts/exp001/submissions/submission.csv"
)
print(validation["valid"])  # True/False
```

**ì£¼ìš” ê¸°ëŠ¥**:
- Top-K í•„í„°ë§
- submission.csv ìƒì„±
- ì œì¶œ íŒŒì¼ ê²€ì¦
- DataFrame ë³€í™˜

---

## ğŸ”— ëª¨ë“ˆ ê°„ ê´€ê³„

```
scripts/
  â†“ (ì‚¬ìš©)
src/
  â”œâ”€â”€ utils.py          â† ëª¨ë“  ëª¨ë“ˆì´ ì‚¬ìš©
  â”œâ”€â”€ data_loader.py    â† COCODataset, YOLO wrapper
  â”œâ”€â”€ model.py          â† YOLOModel (Ultralytics ë˜í¼)
  â”œâ”€â”€ trainer.py        â† utils + model (í•™ìŠµ ì‹¤í–‰)
  â””â”€â”€ inference.py      â† model (ì¶”ë¡  ì‹¤í–‰)
```

---

## âœ… ì „ì²´ ì›Œí¬í”Œë¡œìš° ì˜ˆì‹œ

```python
# 1. ê²½ë¡œ ì„¤ì •
from src.utils import setup_project_paths, set_seed, load_config

paths = setup_project_paths("exp001", create_dirs=True)
set_seed(42)
config = load_config("configs/experiments/exp001_baseline.yaml")

# 2. ë°ì´í„° ë¡œë”©
from src.data_loader import YOLODatasetWrapper

yolo_data = YOLODatasetWrapper(paths["DATA"] / "datasets/exp001_yolo/data.yaml")
print(f"Classes: {yolo_data.get_num_classes()}")

# 3. í•™ìŠµ
from src.trainer import Trainer

trainer = Trainer(run_name="exp001", config=config)
trainer.train(data_yaml=yolo_data.get_data_yaml_path())

# 4. í‰ê°€
eval_results = trainer.evaluate(split="val")

# 5. ì¶”ë¡ 
from src.inference import Inferencer

inferencer = Inferencer(checkpoint_path=paths["CKPT"] / "best.pt")
results = inferencer.predict_and_filter_top_k(
    source=paths["TEST_IMAGES"],
    top_k=4,
    conf=0.25,
)

# 6. ì œì¶œ íŒŒì¼ ìƒì„±
inferencer.create_submission_csv(
    results=results,
    output_path=paths["SUBMISSIONS"] / "submission.csv",
    top_k=4,
)
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥:

```bash
# utils.py í…ŒìŠ¤íŠ¸
python src/utils.py

# data_loader.py í…ŒìŠ¤íŠ¸
python src/data_loader.py

# model.py í…ŒìŠ¤íŠ¸
python src/model.py

# trainer.py í…ŒìŠ¤íŠ¸
python src/trainer.py

# inference.py í…ŒìŠ¤íŠ¸
python src/inference.py
```

---

## ğŸ“Š ì½”ë“œ í†µê³„

- **utils.py**: 19KB, 600+ lines
- **data_loader.py**: 8.4KB, 280+ lines
- **model.py**: 9.1KB, 300+ lines
- **trainer.py**: 10KB, 330+ lines
- **inference.py**: 9.9KB, 320+ lines

**ì´ ì½”ë“œëŸ‰**: ~56KB, 1,830+ lines

---

## ğŸ”§ í™•ì¥ ê°€ëŠ¥ì„±

### í–¥í›„ ì¶”ê°€ ê°€ëŠ¥í•œ ê¸°ëŠ¥

1. **data_loader.py**
   - Custom augmentation pipeline
   - Multi-scale training support
   - Cached dataset (faster loading)

2. **model.py**
   - Ensemble ëª¨ë¸ ì§€ì›
   - TTA (Test-Time Augmentation)
   - Model pruning/quantization

3. **trainer.py**
   - Multi-GPU í•™ìŠµ (DDP)
   - Mixed precision training (AMP)
   - Learning rate finder

4. **inference.py**
   - Batch inference optimization
   - Visualization tools
   - Uncertainty estimation

---

**êµ¬í˜„ ì™„ë£Œ**: 2026-02-05  
**ë‹´ë‹¹**: @DM  
**ìƒíƒœ**: Stage 2 (src ëª¨ë“ˆ) ì™„ë£Œ âœ…
