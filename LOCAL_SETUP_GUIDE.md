# ğŸ  ë¡œì»¬ í™˜ê²½ ì‹¤í—˜ ê°€ì´ë“œ

ì´ ê°€ì´ë“œëŠ” ë¡œì»¬ ì»´í“¨í„°ì—ì„œ YOLOv8 ë² ì´ìŠ¤ë¼ì¸ ì‹¤í—˜ì„ ì‹œì‘í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ“‹ **ì‚¬ì „ ì¤€ë¹„ ì²´í¬ë¦¬ìŠ¤íŠ¸**

- [ ] Python 3.8 ì´ìƒ ì„¤ì¹˜
- [ ] Git ì„¤ì¹˜
- [ ] CUDA ì§€ì› GPU (ê¶Œì¥, CPUë„ ê°€ëŠ¥í•˜ì§€ë§Œ ëŠë¦¼)
- [ ] ìµœì†Œ 10GB ì—¬ìœ  ê³µê°„
- [ ] ë°ì´í„° íŒŒì¼ ì¤€ë¹„ (232 train images, 763 annotations, 842 test images)

---

## ğŸš€ **1ë‹¨ê³„: ì½”ë“œ ê°€ì ¸ì˜¤ê¸°**

```bash
# 1. ë ˆí¬ì§€í† ë¦¬ í´ë¡ 
git clone https://github.com/ming2tofu33/pjt-sprint_ai07_healthcare.git
cd pjt-sprint_ai07_healthcare

# 2. feat/DM-refactor ë¸Œëœì¹˜ë¡œ ì „í™˜
git checkout feat/DM-refactor

# 3. ìµœì‹  ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
git pull origin feat/DM-refactor

# 4. í”„ë¡œì íŠ¸ êµ¬ì¡° í™•ì¸
ls -la
```

---

## ğŸ”§ **2ë‹¨ê³„: Python í™˜ê²½ ì„¤ì •**

### **ë°©ë²• A: Conda (ê¶Œì¥)**

```bash
# 1. ìƒˆ í™˜ê²½ ìƒì„±
conda create -n pill_detection python=3.10 -y
conda activate pill_detection

# 2. PyTorch ì„¤ì¹˜ (CUDA 12.1)
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y

# 3. ë‚˜ë¨¸ì§€ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install ultralytics pandas numpy PyYAML scikit-learn matplotlib seaborn albumentations

# 4. ì„¤ì¹˜ í™•ì¸
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

### **ë°©ë²• B: venv**

```bash
# 1. ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv

# 2. í™œì„±í™”
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install ultralytics pandas numpy PyYAML scikit-learn matplotlib seaborn albumentations

# 4. ì„¤ì¹˜ í™•ì¸
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

### **ë°©ë²• C: pipë§Œ ì‚¬ìš©**

```bash
# 1. PyTorch ì„¤ì¹˜
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 2. ë‚˜ë¨¸ì§€ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install ultralytics pandas numpy PyYAML scikit-learn matplotlib seaborn albumentations
```

---

## ğŸ“ **3ë‹¨ê³„: ë°ì´í„° ì„¤ì •**

### **ì˜µì…˜ A: ìë™ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ì¶”ì²œ)**

```bash
# 1. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
bash setup_local_data.sh

# 2. í”„ë¡¬í”„íŠ¸ê°€ ë‚˜ì˜¤ë©´ ë°ì´í„°ê°€ ìˆëŠ” ê²½ë¡œ ì…ë ¥
# ì˜ˆ: /home/user/downloads/pill_data
# ë˜ëŠ”: ../my_data

# 3. ìë™ìœ¼ë¡œ ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„±ë¨
```

### **ì˜µì…˜ B: ìˆ˜ë™ ì„¤ì •**

```bash
# 1. ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p data/raw

# 2. ë°ì´í„°ê°€ ë‹¤ë¥¸ ìœ„ì¹˜ì— ìˆë‹¤ë©´ ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„±
ln -s /path/to/your/train_images data/raw/train_images
ln -s /path/to/your/train_annotations data/raw/train_annotations
ln -s /path/to/your/test_images data/raw/test_images

# 3. ë°ì´í„° í™•ì¸
ls -la data/raw/
```

### **ì˜µì…˜ C: ë°ì´í„° ë³µì‚¬ (ì¶©ë¶„í•œ ê³µê°„ì´ ìˆë‹¤ë©´)**

```bash
# ë°ì´í„°ë¥¼ í”„ë¡œì íŠ¸ í´ë”ë¡œ ë³µì‚¬
cp -r /path/to/your/train_images data/raw/
cp -r /path/to/your/train_annotations data/raw/
cp -r /path/to/your/test_images data/raw/
```

### **ë°ì´í„° êµ¬ì¡° í™•ì¸**

```bash
# ì˜ˆìƒë˜ëŠ” êµ¬ì¡°:
tree data/raw/ -L 2

# ì¶œë ¥ ì˜ˆì‹œ:
# data/raw/
# â”œâ”€â”€ train_images/          (232 files)
# â”‚   â”œâ”€â”€ K-001900-016548-019607-029451_0_2_0_2_70_000_200.png
# â”‚   â””â”€â”€ ...
# â”œâ”€â”€ train_annotations/     (114 folders, 763 JSON files)
# â”‚   â”œâ”€â”€ K-001900-016548-019607-029451_json/
# â”‚   â”‚   â”œâ”€â”€ K-001900/
# â”‚   â”‚   â”‚   â””â”€â”€ K-001900-016548-019607-029451_0_2_0_2_70_000_200.json
# â”‚   â””â”€â”€ ...
# â””â”€â”€ test_images/           (842 files)
#     â”œâ”€â”€ test_001.png
#     â””â”€â”€ ...

# íŒŒì¼ ê°œìˆ˜ í™•ì¸
echo "Train images: $(find data/raw/train_images -type f | wc -l)"
echo "Train annotations: $(find data/raw/train_annotations -name "*.json" | wc -l)"
echo "Test images: $(find data/raw/test_images -type f | wc -l)"

# ì˜ˆìƒ ì¶œë ¥:
# Train images: 232
# Train annotations: 763
# Test images: 842
```

---

## ğŸ¯ **4ë‹¨ê³„: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (5ë¶„)**

ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‘ì€ ë°ì´í„°ë¡œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸í•´ë´…ë‹ˆë‹¤.

```bash
# 1. COCO í¬ë§· ìƒì„± (1ë¶„)
python scripts/1_create_coco_format.py \
    --train_images data/raw/train_images \
    --train_annotations data/raw/train_annotations \
    --output_dir data/coco_data \
    --validate

# ì¶œë ¥ í™•ì¸:
# âœ… Merged COCO JSON saved to: data/coco_data/merged_coco.json
# âœ… Category mapping saved to: data/coco_data/category_mapping.json

# 2. ë°ì´í„° ë¶„í•  (30ì´ˆ)
python scripts/0_splitting.py \
    --coco_json data/coco_data/merged_coco.json \
    --output_dir data/splits \
    --train_ratio 0.8 \
    --stratify_by object_count

# ì¶œë ¥ í™•ì¸:
# âœ… Split info saved to: data/splits/split_info.json

# 3. YOLO ë°ì´í„°ì…‹ ì¤€ë¹„ (1ë¶„)
python scripts/2_prepare_yolo.py \
    --coco_dir data/coco_data \
    --images_dir data/raw/train_images \
    --splits_dir data/splits \
    --output_dir data/yolo_data \
    --symlink

# ì¶œë ¥ í™•ì¸:
# âœ… YOLO dataset created at: data/yolo_data
# âœ… data.yaml saved

# 4. ì„¤ì • íŒŒì¼ í™•ì¸
cat data/yolo_data/data.yaml

# 5. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í•™ìŠµ (1 epoch, 2ë¶„)
python scripts/3_train.py \
    --config configs/experiments/exp001_baseline.yaml \
    --epochs 1 \
    --batch_size 8

# ì¶œë ¥ í™•ì¸:
# âœ… Training completed
# âœ… Best model saved to: runs/exp001_*/checkpoints/best.pt
```

**âœ… í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí•˜ë©´ ë³¸ê²©ì ì¸ ì‹¤í—˜ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!**

---

## ğŸƒ **5ë‹¨ê³„: ì‹¤ì œ ì‹¤í—˜ ì‹œì‘**

### **ì‹¤í—˜ 1: YOLOv8n ë² ì´ìŠ¤ë¼ì¸ (1-2ì‹œê°„)**

```bash
# 1. ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµ (50 epochs)
python scripts/3_train.py \
    --config configs/experiments/exp001_baseline.yaml

# 2. í•™ìŠµ ëª¨ë‹ˆí„°ë§ (ìƒˆ í„°ë¯¸ë„ì—ì„œ)
tail -f runs/exp001_*/logs/exp001.log

# 3. í•™ìŠµ ì™„ë£Œ í›„ í‰ê°€
python scripts/4_evaluate.py \
    --checkpoint runs/exp001_*/checkpoints/best.pt \
    --data_yaml data/yolo_data/data.yaml

# 4. Kaggle ì œì¶œ íŒŒì¼ ìƒì„±
python scripts/5_submission.py \
    --checkpoint runs/exp001_*/checkpoints/best.pt \
    --test_images data/raw/test_images \
    --category_mapping data/coco_data/category_mapping.json

# 5. ìƒì„±ëœ CSV í™•ì¸
ls -lh submissions/
head -20 submissions/submission_exp001_*.csv
```

### **ì‹¤í—˜ 2: YOLOv8s í™•ì¥ (2-4ì‹œê°„)**

```bash
# ë” í° ëª¨ë¸ë¡œ í•™ìŠµ
python scripts/3_train.py \
    --config configs/experiments/exp002_yolov8s_extended.yaml

# í‰ê°€ ë° ì œì¶œ
python scripts/4_evaluate.py \
    --checkpoint runs/exp002_*/checkpoints/best.pt \
    --data_yaml data/yolo_data/data.yaml

python scripts/5_submission.py \
    --checkpoint runs/exp002_*/checkpoints/best.pt \
    --test_images data/raw/test_images \
    --category_mapping data/coco_data/category_mapping.json
```

### **ì‹¤í—˜ 3: ê³ í•´ìƒë„ í•™ìŠµ (4-8ì‹œê°„)**

```bash
# 1280 ì´ë¯¸ì§€ í¬ê¸°ë¡œ í•™ìŠµ
python scripts/3_train.py \
    --config configs/experiments/exp003_yolov8m_highres.yaml
```

---

## ğŸ“Š **6ë‹¨ê³„: ê²°ê³¼ í™•ì¸ ë° ë¶„ì„**

### **í•™ìŠµ ê²°ê³¼ í™•ì¸**

```bash
# 1. ì‹¤í—˜ ë””ë ‰í† ë¦¬ í™•ì¸
ls -la runs/

# 2. ë¡œê·¸ í™•ì¸
cat runs/exp001_*/logs/exp001.log | tail -50

# 3. í‰ê°€ ê²°ê³¼ í™•ì¸
cat evaluation_results/summary.txt

# 4. ì œì¶œ íŒŒì¼ í™•ì¸
cat submissions/submission_exp001_*.csv | head -20
```

### **ì‹œê°í™” (ì„ íƒì‚¬í•­)**

```python
# Jupyter Notebook ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì—ì„œ
import pandas as pd
import matplotlib.pyplot as plt

# ì œì¶œ íŒŒì¼ ë¶„ì„
df = pd.read_csv('submissions/submission_exp001_*.csv')
print(f"Total detections: {len(df)}")
print(f"Unique images: {df['image_id'].nunique()}")
print(f"Avg detections per image: {len(df) / df['image_id'].nunique():.2f}")

# ì ìˆ˜ ë¶„í¬
df['score'].hist(bins=50)
plt.xlabel('Confidence Score')
plt.ylabel('Count')
plt.title('Detection Score Distribution')
plt.show()
```

---

## ğŸ”§ **ì»¤ìŠ¤í…€ ì‹¤í—˜í•˜ê¸°**

### **ìì‹ ë§Œì˜ ì‹¤í—˜ config ë§Œë“¤ê¸°**

```bash
# 1. ê¸°ì¡´ config ë³µì‚¬
cp configs/experiments/exp001_baseline.yaml configs/experiments/exp_mytest.yaml

# 2. config ìˆ˜ì • (í…ìŠ¤íŠ¸ ì—ë””í„°ë¡œ)
vim configs/experiments/exp_mytest.yaml
# ë˜ëŠ”
code configs/experiments/exp_mytest.yaml

# 3. ìˆ˜ì • ì˜ˆì‹œ:
# experiment:
#   name: "mytest"
#   model_variant: "yolov8s"  # n â†’ së¡œ ë³€ê²½
#   epochs: 100               # 50 â†’ 100ìœ¼ë¡œ ì¦ê°€
#   description: "My custom experiment"

# 4. ì‹¤í—˜ ì‹¤í–‰
python scripts/3_train.py --config configs/experiments/exp_mytest.yaml
```

### **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**

```bash
# CLIë¡œ ë°”ë¡œ ì˜¤ë²„ë¼ì´ë“œ
python scripts/3_train.py \
    --config configs/experiments/exp001_baseline.yaml \
    --epochs 150 \
    --batch_size 32 \
    --lr 0.0005 \
    --image_size 1280
```

### **ì œì¶œ íŒŒì¼ íŠœë‹**

```bash
# Confidence threshold ì¡°ì •
python scripts/5_submission.py \
    --checkpoint runs/exp001_*/checkpoints/best.pt \
    --test_images data/raw/test_images \
    --category_mapping data/coco_data/category_mapping.json \
    --conf_threshold 0.15  # ê¸°ë³¸ê°’: 0.25

# NMS threshold ì¡°ì •
python scripts/5_submission.py \
    --checkpoint runs/exp001_*/checkpoints/best.pt \
    --test_images data/raw/test_images \
    --category_mapping data/coco_data/category_mapping.json \
    --iou_nms 0.40  # ê¸°ë³¸ê°’: 0.45

# TTA (Test Time Augmentation) ì ìš©
python scripts/5_submission.py \
    --checkpoint runs/exp001_*/checkpoints/best.pt \
    --test_images data/raw/test_images \
    --category_mapping data/coco_data/category_mapping.json \
    --tta  # ì ìˆ˜ í–¥ìƒ, ì‹œê°„ 4ë°° ì¦ê°€
```

---

## ğŸ› **ë¬¸ì œ í•´ê²° (Troubleshooting)**

### **ë¬¸ì œ 1: CUDA out of memory**

```bash
# í•´ê²°ì±…: batch_size ì¤„ì´ê¸°
python scripts/3_train.py \
    --config configs/experiments/exp001_baseline.yaml \
    --batch_size 8  # ê¸°ë³¸ê°’ 16ì—ì„œ 8ë¡œ ê°ì†Œ

# ë˜ëŠ” image_size ì¤„ì´ê¸°
python scripts/3_train.py \
    --config configs/experiments/exp001_baseline.yaml \
    --image_size 640  # 1280ì—ì„œ 640ìœ¼ë¡œ ê°ì†Œ
```

### **ë¬¸ì œ 2: ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ**

```bash
# ë°ì´í„° ê²½ë¡œ í™•ì¸
ls -la data/raw/train_images
ls -la data/raw/train_annotations
ls -la data/raw/test_images

# íŒŒì¼ ê°œìˆ˜ í™•ì¸
find data/raw/train_images -type f | wc -l  # 232 ì˜ˆìƒ
find data/raw/train_annotations -name "*.json" | wc -l  # 763 ì˜ˆìƒ
find data/raw/test_images -type f | wc -l  # 842 ì˜ˆìƒ

# ì‹¬ë³¼ë¦­ ë§í¬ê°€ ê¹¨ì¡Œë‹¤ë©´ ë‹¤ì‹œ ìƒì„±
rm -rf data/raw/train_images data/raw/train_annotations data/raw/test_images
bash setup_local_data.sh
```

### **ë¬¸ì œ 3: í•™ìŠµì´ ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ**

```bash
# 1. Learning rate ê°ì†Œ
python scripts/3_train.py \
    --config configs/experiments/exp001_baseline.yaml \
    --lr 0.0005  # ê¸°ë³¸ê°’ 0.001ì—ì„œ ê°ì†Œ

# 2. Warmup epochs ì¦ê°€
python scripts/3_train.py \
    --config configs/experiments/exp001_baseline.yaml \
    --warmup_epochs 5

# 3. ë°ì´í„° ê²€ì¦
python scripts/1_create_coco_format.py \
    --train_images data/raw/train_images \
    --train_annotations data/raw/train_annotations \
    --output_dir data/coco_data \
    --validate \
    --verbose
```

### **ë¬¸ì œ 4: ì œì¶œ íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜**

```bash
# ì œì¶œ íŒŒì¼ ê²€ì¦
python -c "
import pandas as pd

# CSV ë¡œë“œ
df = pd.read_csv('submissions/submission_exp001_*.csv')

# ê¸°ë³¸ ì •ë³´
print(f'Total rows: {len(df)}')
print(f'Columns: {list(df.columns)}')
print(f'Unique images: {df[\"image_id\"].nunique()}')

# ê²€ì¦
print('\\nValidation:')
print(f'  Duplicate annotation_ids: {df[\"annotation_id\"].duplicated().sum()}')
print(f'  Negative bbox values: {(df[[\"bbox_x\",\"bbox_y\",\"bbox_w\",\"bbox_h\"]] < 0).sum().sum()}')
print(f'  Max detections per image: {df.groupby(\"image_id\").size().max()}')
print(f'  Score range: [{df[\"score\"].min():.3f}, {df[\"score\"].max():.3f}]')

# ìƒ˜í”Œ
print('\\nFirst 5 rows:')
print(df.head())
"
```

---

## ğŸ“ **ì²´í¬ë¦¬ìŠ¤íŠ¸: ì²« ì œì¶œ ì „**

ì‹¤ì œë¡œ Kaggleì— ì œì¶œí•˜ê¸° ì „ í™•ì¸ì‚¬í•­:

- [ ] ëª¨ë¸ì´ ìˆ˜ë ´í–ˆëŠ”ê°€? (validation lossê°€ ì•ˆì •í™”ë¨)
- [ ] mAP@0.75-0.95 > 0.30 ë‹¬ì„±í–ˆëŠ”ê°€?
- [ ] ì œì¶œ CSVê°€ ìƒì„±ë˜ì—ˆëŠ”ê°€?
- [ ] CSV validation í†µê³¼í–ˆëŠ”ê°€? (ìœ„ì˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰)
- [ ] category_mapping.json ì‚¬ìš©ë˜ì—ˆëŠ”ê°€?
- [ ] bbox í˜•ì‹ì´ ì ˆëŒ€ ì¢Œí‘œì¸ê°€? (ì •ê·œí™”ë˜ì§€ ì•ŠìŒ)
- [ ] image_idê°€ ì˜¬ë°”ë¥´ê²Œ ì¶”ì¶œë˜ì—ˆëŠ”ê°€?
- [ ] ì´ 842ê°œ test ì´ë¯¸ì§€ ì²˜ë¦¬ë˜ì—ˆëŠ”ê°€?
- [ ] ì´ë¯¸ì§€ë‹¹ í‰ê·  2-3ê°œ detectionì´ ìˆëŠ”ê°€?

**ëª¨ë‘ ì²´í¬í–ˆë‹¤ë©´ Kaggleì— ì œì¶œí•˜ì„¸ìš”! ğŸš€**

---

## ğŸ¯ **ë‹¤ìŒ ë‹¨ê³„**

### **ì ìˆ˜ í–¥ìƒì„ ìœ„í•œ ì•„ì´ë””ì–´**

1. **ëª¨ë¸ í¬ê¸° ì¦ê°€**
   - YOLOv8n â†’ YOLOv8s â†’ YOLOv8m

2. **ì´ë¯¸ì§€ í¬ê¸° ì¦ê°€**
   - 640 â†’ 1280 (ì‘ì€ ê°ì²´ ê²€ì¶œ í–¥ìƒ)

3. **í•™ìŠµ epoch ì¦ê°€**
   - 50 â†’ 100 â†’ 150 epochs

4. **Threshold íŠœë‹**
   - confidence threshold: 0.15, 0.20, 0.25, 0.30, 0.35
   - NMS threshold: 0.40, 0.45, 0.50

5. **Test Time Augmentation**
   - `--tta` í”Œë˜ê·¸ ì‚¬ìš©

6. **ì•™ìƒë¸”**
   - ì—¬ëŸ¬ ëª¨ë¸ í•™ìŠµ í›„ ì˜ˆì¸¡ ê²°í•©

---

## ğŸ’¡ **ìœ ìš©í•œ ëª…ë ¹ì–´ ëª¨ìŒ**

```bash
# GPU ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# í•™ìŠµ ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f runs/exp001_*/logs/exp001.log

# ë””ìŠ¤í¬ ìš©ëŸ‰ í™•ì¸
du -sh data/* runs/*

# íŠ¹ì • ì‹¤í—˜ ê²°ê³¼ë§Œ ë³´ê¸°
ls -lh runs/exp001_*

# ëª¨ë“  ì œì¶œ íŒŒì¼ ë³´ê¸°
ls -lh submissions/

# ê°€ì¥ ìµœê·¼ ì‹¤í—˜ ì°¾ê¸°
ls -lt runs/ | head -5
```

---

## ğŸ“š **ì°¸ê³  ë¬¸ì„œ**

- **ì „ì²´ ê°€ì´ë“œ**: `docs/IMPLEMENTATION_COMPLETE.md`
- **í”„ë¡œì íŠ¸ ìƒíƒœ**: `PROJECT_STATUS.md`
- **Phase 1**: `docs/PHASE1_COMPLETE.md`
- **Phase 2**: `docs/PHASE2_COMPLETE.md`
- **Phase 3**: `docs/PHASE3_COMPLETE.md`
- **Phase 4 & 5**: `docs/PHASE4_5_COMPLETE.md`

---

## ğŸ¤ **ë„ì›€ì´ í•„ìš”í•˜ë©´**

1. ë¬¸ì„œ í™•ì¸: `docs/` í´ë”
2. ë¡œê·¸ í™•ì¸: `runs/exp00X_*/logs/`
3. Config í™•ì¸: `config_snapshot.yaml`
4. GitHub Issuesì— ì§ˆë¬¸ ì˜¬ë¦¬ê¸°

---

**í–‰ìš´ì„ ë¹•ë‹ˆë‹¤! ğŸ†**

ì¢‹ì€ ì ìˆ˜ ë°›ìœ¼ì„¸ìš”! ğŸ’ª
